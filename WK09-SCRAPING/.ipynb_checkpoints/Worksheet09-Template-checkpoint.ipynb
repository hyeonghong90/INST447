{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 10 - Getting started with Web Scraping\n",
    "  \n",
    "Your Name: Hyeong-gi Hong      \n",
    "Your Class: INST 447  \n",
    "Your Section: 0101 (MWF) | 0102 (TTh)  \n",
    "Your favorite flavor of Frozen Yogurt, Ice Cream, Sorbet, or Other: Vanilla  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Reflection  \n",
    "\n",
    "Write a 75 word (+/- 15 words) response about the two assigned readings: \n",
    "\n",
    "\n",
    "> “Bots Are Scraping Your Data For Cash Amid Murky Laws And Ethics.” Accessed March 15, 2018. https://www.fastcompany.com/40456140/bots-are-scraping-your-public-data-for-cash-amid-murky-laws-and-ethics-linkedin-hiq (Links to an external site.).\n",
    "\n",
    "> Fiesler, Casey. “Law & Ethics of Scraping: What HiQ v LinkedIn Could Mean for Researchers Violating TOS.” Medium (blog), August 15, 2017. https://medium.com/@cfiesler/law-ethics-of-scraping-what-hiq-v-linkedin-could-mean-for-researchers-violating-tos-787bd3322540 (Links to an external site.).\n",
    "\n",
    "Prompting questions to get your brain moving:\n",
    "<ol>\n",
    "<li>What are your thoughts about the ethics of scraping?</li>\n",
    "<li>How would you feel if you found that your content was being scraped?</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my opinion, people should follow the basic rule of ethics of scraping such as not taking information that are not authorized. As a student researcher, I have also scraped a few websites for my school research projects, yet the data was available for the public, and it does not say that I cannot scrape the website as well. \n",
    "If it is involving my personal content that should not be shared without my consent, I would be very uncomfortable. It is not only illegal but also not ethical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Testudo\n",
    "\n",
    "URL: https://app.testudo.umd.edu/\n",
    "\n",
    "## Check if we can scrape!\n",
    "\n",
    "We need to answeer all 3 of the below:\n",
    "<ol>\n",
    "<li>Is there a robots.txt file?</li>\n",
    "<li>Is there a robots meta tag that prohibits scraping? (http://www.robotstxt.org/meta.html)</li>\n",
    "<li>Is there an X-Robots-Tag in the headder? (https://developers.google.com/search/reference/robots_meta_tag)</li>\n",
    "</ol>\n",
    "\n",
    "We will also check to see if there is a licensing agreement prohibiting the use of this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Check for robots.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testudo_url = \"https://app.testudo.umd.edu/robots.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(testudo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Is there a robots meta tag?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta tags can appear on any html page, so we should check every page, so we should right a function to check if there are meta tags on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testudo_url = \"https://app.testudo.umd.edu/\"\n",
    "r = requests.get(testudo_url)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed = BeautifulSoup(r.text, 'lxml')\n",
    "type(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<meta charset=\"utf-8\"/>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.find_all('meta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Is there an X-Robots-Tag in the header?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'X-Robots-Tag' in r.headers.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not programming, but looking:\n",
    "Are there policies or licensing agreements that prevent or allow our scraping of the data?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a policy / rule, but it does not mention anything about scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What iSchool Classes are listed on Testudo for Fall 2018?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is getting close to registration time. Wouldn't it be nice to be able to have a way to be told automatically if they change the courses listed?  \n",
    "\n",
    "The URL I have provided goes straight to the course listings for the INST Fall 2018 Semester course listings. We'll need to parse the page and get a list of the courses and the sections and the times each section meets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testudo_url = \"https://app.testudo.umd.edu/soc/201808/INST\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First get the page.\n",
    "\n",
    "<ol><li>Get the page.</li>\n",
    "<li>Check the response status.</li>\n",
    "<li>Parse the response with BeautifulSoup</li>\n",
    "<li>Check if there is a robots meta.</li>\n",
    "<li>Check if there is a 'x-robots-tag' in the header response.</li></ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(testudo_url)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = BeautifulSoup(r.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = parsed.find_all('div', attrs={'class': 'course'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = parsed.select('div.course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "course = courses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_id = course.select_one('.course-id').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#course.select_one('.course-title').text\n",
    "course_title = course.find(attrs={'class':'course-title'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_credit = course.select_one('.course-min-credits').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the elements to grab.\n",
    "\n",
    "In your browser, use the inspector to find the element that contains each course.\n",
    "\n",
    "What element contains each course?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now get a list of each of those elements from the parsed html\n",
    "\n",
    "How many do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's test on the first course\n",
    "\n",
    "Create a dictionary that contains:  \n",
    "- Course ID\n",
    "- Course Title\n",
    "- Course Credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading sections:\n",
    "The sections are kept on a separate page and loaded with JavaScript:  \n",
    "\n",
    "> https://app.testudo.umd.edu/soc/201808/sections?courseIds=<course-id\\>  \n",
    "    \n",
    "You need to replace the <course-id\\> with the course id of the course whose sections you want to lookup.\n",
    "\n",
    "\n",
    "Make a request to get the sections for that first course that you worked with and parse that response.\n",
    "We will then add the sections' information to the dictionary you created above for the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the request\n",
    "With requests.get we can build the query string (the part after the '?') by using a dictionary as the second argumnet. This makes building complex queries much easier over time and prevents you from passing the same key multiple times.\n",
    "\n",
    "We do this like:\n",
    "> requests.get(url, {'key', 'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://app.testudo.umd.edu/soc/201808/sections', \n",
    "            {'courseIds': 'INST126'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sect = BeautifulSoup(r.text, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a parse 'soup' object from the response with BeaufulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the section's container element\n",
    "\n",
    "Go to your browser and find the container element that holds each section's info. Then create a list with each section in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_dict = sect.select('div.delivery-f2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(section_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now get the info for each section.\n",
    "Save the section_id, instructor, and days with time that the class meets. \n",
    "Save each section into the dictionary that you used for the course.\n",
    "\n",
    "You should end up with a data structure that looks like:\n",
    "<pre>\n",
    "[{'instructor': ['Instructor Name'],\n",
    "  'meeting_place': 'BUILDING ROOM#',\n",
    "  'meeting_time': 'DAYS TIME',\n",
    "  'section_id': 'SECTION_ID'}]\n",
    "</pre>\n",
    "That is a list that contains a dictionary for each section. Note that the key 'instructor' is also a list because sometimes there are muliple instructors for a section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_section = section_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_id = first_section.select_one('.section-id').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATL\\n1113'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_section.select_one('.class-building').text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the sections to the course dictionary\n",
    "\n",
    "Add the sections information to the course information so that you end up with a structure like:\n",
    "\n",
    "<pre>\n",
    "{'course_credits': 'NUM CREDITS',\n",
    " 'course_id': 'COURSE_ID',\n",
    " 'course_title': 'COURSE_TITLE',\n",
    " 'sections': [{'instructor': ['INSTRUCTOR NAME'],\n",
    "   'meeting_place': 'BUILDING ROOM#',\n",
    "   'meeting_time': 'DAYS TIME',\n",
    "   'section_id': 'SECTION_ID'}]}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect them All!\n",
    "\n",
    "Ok, so you've just collected the info for a single course. Now do it for all of the courses for INST.\n",
    "\n",
    "The result should be a data structure that when printed looks like:\n",
    "\n",
    "<pre>\n",
    "[{'course_id': 'COURSE_ID',\n",
    " 'course_title': 'COURSE_TITLE',\n",
    " 'course_credits': 'NUM CREDITS',\n",
    " 'sections': [{'instructor': ['INSTRUCTOR NAME'],\n",
    "   'meeting_place': 'BUILDING ROOM#',\n",
    "   'meeting_time': 'DAYS TIME',\n",
    "   'section_id': 'SECTION_ID'}]}\n",
    "]\n",
    "</pre>\n",
    "That is a list that contains a dictionary. The dictionary contains the information for the course and has a key called sections. The key sections contains a list of dictionaries that contain each sections' information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
